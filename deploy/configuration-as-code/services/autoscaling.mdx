---
title: 'Autoscaling Configuration'
sidebarTitle: 'Autoscaling'
---

Configure horizontal pod autoscaling to automatically adjust the number of replicas based on resource utilization.

## Field Reference

| Field | Type | Description |
|-------|------|-------------|
| `enabled` | boolean | Enable autoscaling |
| `minInstances` | integer | Minimum number of replicas |
| `maxInstances` | integer | Maximum number of replicas |
| `cpuThresholdPercent` | integer | CPU usage threshold (0-100) |
| `memoryThresholdPercent` | integer | Memory usage threshold (0-100) |

## Basic Configuration

```yaml
services:
  - name: api
    type: web
    run: node server.js
    port: 8080
    cpuCores: 1
    ramMegabytes: 1024
    autoscaling:
      enabled: true
      minInstances: 2
      maxInstances: 10
      cpuThresholdPercent: 80
      memoryThresholdPercent: 80
```

<Info>
When autoscaling is enabled, the `instances` field is ignored. The autoscaler manages replica count automatically.
</Info>

<Tip>
For high availability, set `minInstances` to at least 3. See [High Availability Applications](/configure/zero-downtime-deployments#high-availability-applications) for more details.
</Tip>

## How It Works

When either CPU or memory usage exceeds your configured threshold, Porter automatically adds replicas. When usage drops, replicas are removed (down to your minimum).

For example, with an 80% CPU threshold:
- If average CPU across pods exceeds 80%, new replicas are added
- If average CPU drops below 80%, excess replicas are removed
- The system maintains headroom for traffic spikes

## Custom Metrics Autoscaling (Prometheus)

Scale based on application-specific metrics like queue length, request latency, or custom business metrics.

| Field | Type | Description |
|-------|------|-------------|
| `customAutoscaling.prometheusMetricCustomAutoscaling.metricName` | string | Prometheus metric name |
| `customAutoscaling.prometheusMetricCustomAutoscaling.threshold` | number | Threshold value to trigger scaling |
| `customAutoscaling.prometheusMetricCustomAutoscaling.query` | string | Custom PromQL query (optional, defaults to metric name) |

```yaml
services:
  - name: api
    type: web
    run: node server.js
    port: 8080
    cpuCores: 1
    ramMegabytes: 1024
    autoscaling:
      enabled: true
      minInstances: 1
      maxInstances: 10
      customAutoscaling:
        prometheusMetricCustomAutoscaling:
          metricName: "http_requests_per_second"
          threshold: 100
          query: "rate(http_requests_total[5m])"
```

<Info>
Custom metrics autoscaling requires Prometheus to be accessible in your cluster. See [Custom Metrics and Autoscaling](/observability/custom-metrics-and-autoscaling) for setup details.
</Info>

## Temporal Autoscaling

Scale Temporal workflow workers based on task queue depth. Porter monitors your Temporal task queues and automatically adjusts worker count.

| Field | Type | Description |
|-------|------|-------------|
| `temporalAutoscaling.temporalIntegrationId` | string | UUID of the Temporal integration |
| `temporalAutoscaling.taskQueue` | string | Name of the Temporal task queue to monitor |
| `temporalAutoscaling.targetQueueSize` | integer | Target number of tasks in queue per replica |

```yaml
services:
  - name: temporal-worker
    type: worker
    run: python worker.py
    cpuCores: 1
    ramMegabytes: 1024
    autoscaling:
      enabled: true
      minInstances: 2
      maxInstances: 50
      temporalAutoscaling:
        temporalIntegrationId: "550e8400-e29b-41d4-a716-446655440000"
        taskQueue: "my-task-queue"
        targetQueueSize: 10
```

<Info>
Temporal autoscaling requires a Temporal integration to be configured. See [Temporal Autoscaling](/configure/temporal-autoscaling) for setup details.
</Info>

## Related Documentation

- [Autoscaling Overview](/configure/autoscaling) - UI-based configuration and concepts
- [Web Services](/deploy/configuration-as-code/services/web-service) - Web service configuration
- [Worker Services](/deploy/configuration-as-code/services/worker-service) - Worker service configuration
